{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network with Keras: Simple example \n",
    "\n",
    "In this example, we classify grayscale images (28 × 28 pixels) of handwritten digits into their 10 categories (0 through 9). We will use the infamous `mNIST` dataset. It's a set of 60,000 training images, plus 10,000 test images, along with all their lables. The set was assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s. \n",
    "\n",
    "As you will see in the code, training a neural network revolves around the following objects:\n",
    "- Layers, which are combined into a network (or model)\n",
    "- The input data and corresponding targets\n",
    "- The loss function, which defines the feedback signal used for learning\n",
    "- The optimizer, which determines how learning proceeds\n",
    "\n",
    "We build the NN by stacking two `Dense` layers on top of each other.\n",
    "\n",
    "**Reference**: Deep Learning with Python by FRANÇOIS CHOLLET\n",
    "\n",
    "**Technical note **: run with Python 3.6 and on my MacBook Pro with macOS Mojave Version 10.14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load mNIST data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training inputs shape (samples, height, width): (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# check the size of the input data (images)\n",
    "print('training inputs shape (samples, height, width):', train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# check data type of input data\n",
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the size of the target data (labels)\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verify that the number of samples is the same for both input and targets\n",
    "assert len(train_labels) == train_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate the target data (should be lables of 0 to 9)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inputs shape (samples, height, width): (10000, 28, 28)\n",
      "what is inside test targets?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate the test inputs and target \n",
    "print('test inputs shape (samples, height, width):', test_images.shape)\n",
    "print('what is inside test targets?')\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQ/w/Jwok5JFsHywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120e2d3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at one of the test images\n",
    "test_digit = test_images[11]\n",
    "plt.imshow(test_digit, cmap=plt.cm.binary)\n",
    "test_digit_label = test_labels[11] \n",
    "print(test_digit_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the NN model archatecture\n",
    "# (1) the layers are sequentially stacked on top of each other\n",
    "network = models.Sequential()\n",
    "# (2) first layer, fully connected, number of hidden units = 512\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "# (3) last/output layer, fully connected, number of hidden units = 10\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "# (4) specifiy optimizer, loss function, & metrics to track during training\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess the data by reshaping it into the shape the network expects\n",
    "# and rescale so that all values are in the [0, 1] interval\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notice that the input images are stored in Numpy tensors, which are \n",
    "# here formatted as float32 tensors of shape (60000, 784) (training data) \n",
    "# and (10000, 784) (test data), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We also need to categorically encode the labels\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.2555 - acc: 0.9254\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1048 - acc: 0.9691\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0688 - acc: 0.9791\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0496 - acc: 0.9850\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0376 - acc: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131cdbf98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model, given the specified archatecture, to the training data\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "# Two quantities are displayed during training: the loss of the network \n",
    "# over the training data, and the accuracy of the network over the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 57us/step\n",
      "test accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "# Check how well the model perfomrs on the test set\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
